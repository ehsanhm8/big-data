---
title: "Are increased incidence of extreme storm events associated with a change in homeowner insurance costs?"
author: 
  - Ryan Altman^[American University Undergraduate Student]
  - Ehsan Habibpour^[American University Graduate Student]
  - Natalie Short^[American University Graduate Student]
format: 
  pdf:
    number-sections: true
    toc: false
    geometry: 
      - top=3cm
date: "`r Sys.Date()`"
date-format: iso
documentclass: article
editor: source
abstract: "Using data from the United States Census Bureau and the National Oceanic and Atmospheric Administration, we examine whether the incidence of extreme storm events is associated with a change in reported homeowner insurance costs."
bibliography: main.bib
---

```{r setup}
#| echo: false
#| message: false

# This chunk loads any packages we need.

library(broom)
library(kableExtra)
library(parameters)
library(tidyverse)
library(xtable)
library(tidycensus)
library(dplyr)
library(tidyr)
library(writexl)
library(readr)
library(stringr)
library(plm)
library(ggplot2)
library(plm)
library(lmtest)
library(sandwich)
library(stargazer)
library(glmnet)
library(Matrix)

# Census data download:

# get census data

get_census_year_data <- function(year_tg, price_index, nt = 2) {

# Define variables

  variables <- c(
    houseowners_total = "B25087_001E", #Housing units
    houseowners_with_mortgage = "B25087_002E", #Housing units with a mortgage
    houseowners_without_mortgage = "B25087_020E", #Housing units without a mortgage
    household_size_average = "B25010_001E", #Average Household Size
    income_median = "B19013_001E", #Median household income in the past 12 months
    house_value_median = "B25077_001E", #Median Value
    owner_cost_median = "B25088_001E", #Median selected monthly owner costs
    owner_cost_median_with_mortgage = "B25088_002E", #same with mortgage
    owner_cost_median_without_mortgage = "B25088_003E", #same without mortgage
    owner_cost_to_income_median = "B25092_001E", #sama as a percentage of yearly income
    owner_cost_to_income_median_with_mortgage = "B25092_002E", #same with mortgage
    owner_cost_to_income_median_without_mortgage = "B25092_003E" #same without mortgage
  )

  census_data <- get_acs(
    geography = "county",
    variables = variables,
    year = year_tg,
    survey = "acs5",
    output = "wide"
  )

  # Process data
  census_data <- census_data %>%
    select(GEOID, NAME, all_of(names(variables))) %>%
    mutate(
      state_fips = as.numeric(substr(GEOID, 1, 2)),    # Extract first 2 digits for state FIPS
      county_fips = as.numeric(substr(GEOID, 3, 5)),   # Extract last 3 digits for county FIPS
      state = sub(".*,\\s*", "", NAME),
      county = sub(",\\s*[^,]*$", "", NAME)
    ) %>%
    mutate(
      county = str_remove(county, " County$"),
      county = str_remove(county, " Census Area$"),
      county = str_remove(county, " Municipio$"),
      county = str_remove(county, " Parish$"),
      county = str_remove(county, " Borough$"),
      county = str_remove(county, " Planning Region$"),
      county = str_remove(county, " city$")
    ) %>%
    mutate(
      income_median = income_median/price_index,
      house_value_median = house_value_median/price_index,
      owner_cost_median = owner_cost_median * 12/price_index,
      owner_cost_median_with_mortgage = owner_cost_median_with_mortgage * 12/price_index,
      owner_cost_median_without_mortgage = owner_cost_median_without_mortgage * 12/price_index,
      year = year_tg
    ) %>%
    select(
      GEOID, state_fips, county_fips, state, county, year, houseowners_total,
      houseowners_with_mortgage, houseowners_without_mortgage, household_size_average,
      house_value_median, owner_cost_median, income_median,
      owner_cost_median_with_mortgage, owner_cost_median_without_mortgage,
      owner_cost_to_income_median, owner_cost_to_income_median_with_mortgage,
      owner_cost_to_income_median_without_mortgage
    )
  
  return(census_data)
}

# Get data for each year
census_data_2023 <- get_census_year_data(2023, 1) 
census_data_2018 <- get_census_year_data(2018, 0.824)
census_data_2013 <- get_census_year_data(2013, 0.765)

# Combine all years into one dataset
census_data_total <- bind_rows(
  census_data_2023,
  census_data_2018,
  census_data_2013
)

# Sort the final dataset
census_data_total <- census_data_total %>%
  arrange(state, county, year)

# NOAA storm and events data download:

noaa_data <- read_csv("../Data/county_events.csv")

noaa_data <- noaa_data |>
  filter(year == 2013 | year == 2018 | year == 2023)

# Joining the census and NOAA datasets:

# Adjusting county names for a join

census_data_total <- census_data_total |>
  mutate(county = str_to_upper(county, locale = "en")) |>
  group_by(state) |>
  arrange(county, .by_group = TRUE) |>
  ungroup()

# Pivoting the NOAA data so each county only appears once

noaa_1_county <- noaa_data |>
  pivot_wider(names_from = event_type, values_from = event_count, 
              values_fill = list(event_count = 0),
              id_cols = c("state_fips_code", "cz_fips_code", "year", "state", "county"))

noaa_1_county <- noaa_1_county |>
  rename(state_bad = state) |>
  mutate(total_events = rowSums(across(where(is.numeric))) - year) |>
  group_by(state_fips_code) |>
  arrange(county, .by_group = TRUE) |>
  ungroup() |>
  mutate(county_state = paste(county, state_fips_code, sep = " -- ")) |>
  mutate(fips_ovr = paste(county, as.character(state_fips_code), as.character(cz_fips_code), sep = "__")) |>
  select(county, fips_ovr, total_events, state_fips_code, county_state, year, everything())

# head(census_data_total)
# head(noaa_1_county)

### Splitting the NOAA event data by year -- not necessarily what we use, but it's good to have them split up.

noaa_2013 <- noaa_1_county |>
  filter(year == 2013)

noaa_2018 <- noaa_1_county |>
  filter(year == 2018)

noaa_2023 <- noaa_1_county |>
  filter(year == 2023)

# head(noaa_2013)
# head(noaa_2018)
# head(noaa_2023)

### Counting the number of counties in each 


print("2013:")
nrow(noaa_2013)
print("2018:")
nrow(noaa_2018)
print("2023:")
nrow(noaa_2023)

### Finding counties that only appear in one year.

exclusive_counties_13 <- setdiff(noaa_2013$fips_ovr, noaa_2018$fips_ovr)
exclusive_counties_13_23 <- setdiff(noaa_2013$fips_ovr, noaa_2023$fips_ovr)
exclusive_counties_13_18_1 <- setdiff(noaa_2023$fips_ovr, noaa_2013$fips_ovr)
exclusive_counties_13_23_1 <- setdiff(noaa_2018$fips_ovr, noaa_2013$fips_ovr)
exclusive_counties_18 <- setdiff(noaa_2018$fips_ovr, noaa_2023$fips_ovr)
exclusive_counties_23 <- setdiff(noaa_2023$fips_ovr, noaa_2018$fips_ovr)
exclusive_counties <- c(exclusive_counties_13, exclusive_counties_13_23, 
                        exclusive_counties_18, exclusive_counties_23,
                        exclusive_counties_13_18_1, exclusive_counties_13_23_1)
length(exclusive_counties)

noaa_2013_bothyearcounties <- noaa_2013 |>
  filter(!(fips_ovr %in% exclusive_counties))

noaa_2018_bothyearcounties <- noaa_2018 |>
  filter(!(fips_ovr %in% exclusive_counties))
  
noaa_2023_bothyearcounties <- noaa_2023 |>
    filter(!(fips_ovr %in% exclusive_counties))

print("Checking the row count:")
print(nrow(noaa_2013_bothyearcounties))
print(nrow(noaa_2018_bothyearcounties))
print(nrow(noaa_2023_bothyearcounties))
```

# Introduction

In recent years, the homeowners insurance market has been disrupted by more extreme weather events - increasing both in storm intensity and incidence - which has made the provision of this insurance unprofitable in many states, resulting in rate hikes or the cessation of coverage altogether \cite{latimes2024insurancecrisis, nyt2023climateinsurance, nyt2024climateinsurancehomes, nyt2024insurancepremiums}. Major insurers State Farm, Farmers, and Allstate have all pulled out of providing homeowners insurance in California. State Farm, previously the largest homeowners insurer in the state, cited “historic increases in construction costs outpacing inflation, rapidly growing catastrophe exposure, and a challenging reinsurance market” when they announced this change in 2023 \cite{statefarm2023california}. In this study, we search for evidence of the second reason by examining whether severe storm event data is correlated with homeowners reported insurance costs. 

# Literature Review

Since extreme weather events are expected to increase in intensity and incidence as climate change worsens, this issue will likely only get worse \cite{ipcc2021chapter11}. However, it is difficult to obtain data on homeowners insurance costs, as state insurance regulators have neglected to collect this data from insurance companies, so it is not possible to see exactly how much these premiums have changed over time, besides relying on anecdotal reports from homeowners \cite{nyt2024naichurdles}.
\cite{Kousky2019role} in a review of disaster insurance markets, points out that while natural disaster losses have been increasing worldwide, there is surprisingly little empirical research on how these events affect insurance costs. This limitation in research is particularly notable when studying the relationship between extreme weather events and homeowner insurance costs, making it difficult to understand how increases in storm frequency might influence insurance markets over time.

In order to integrate citations into the References section below, we add entries into our file `main.bib`. This is a plain-text file that we edit in RStudio (or BibDesk, or similar). We store `main.bib` in the same folder as our paper's `.qmd` and `.pdf` files. Its entries are formatted so that they can be knit to `.pdf`; see [https://j.mp/2UzTXEZ](https://www.overleaf.com/learn/latex/Bibliography_management_with_bibtex#The_bibliography_file) for example entries for articles, books, and miscellaneous. We can get these entries automatically from Google Scholar by turning on BibTeX in the Google Scholar Settings - Bibliography Manager. Perhaps we use a tool like free, open-source BibDesk to help us manage the `.bib` file.

# Data {#sec-data}

We choose two separate datasets to examine this problem. To estimate homeowner insurance costs, we use the American Community Survey, which is part of the US Census and is administered five years. Our unit of analysis is county-year, to estimate the variation in monthly homeowner costs across geography and time.

Our county-level census data comes from the American Community Survey (ACS) 5-year estimates, accessed through the Census Bureau's API. We collect data for three distinct, yearlong periods: 2013, 2018, and 2023. For each county, we extract several housing-related variables including the median monthly owner costs, median house value, median household income, and average household size. The county identification is based on FIPS (Federal Information Processing Standards) codes, which consist of a two-digit state code and a up-to-three-digit county code.

To ensure comparability across different time periods, all monetary values are adjusted for inflation using price indices (with 2023 as the base year, applying indices of 0.765 for 2013 and 0.824 for 2018). Monthly owner costs are annualized by multiplying by 12. The final dataset is created by combining data from all three time periods and organizing it by state, county, and year.

Our dataset includes several key variables: total number of housing units, units with and without mortgages, average household size, median household income, median house value, and median monthly owner costs (separated into categories for properties with and without mortgages). We also collect data on owner costs as a percentage of yearly income, both overall and separated by mortgage status. County names are standardized by removing suffixes such as "County," "Census Area," "Municipio," "Parish," "Borough," "Planning Region," and "City" to ensure consistency across different naming jurisdictions.

It is important to note that while the 2023 ACS included a separate variable for homeowner insurance, this is not available in some years' surveys. In surveys prior to 2023, homeowner fire, hazard, and flood insurance costs are incorporated into a broader measure called "Selected Monthly Owner Costs," which also encompassed real estate taxes, mortgages, utilities, and fuels. To account for these varying components, we include house value in our model as a proxy for real estate taxes and mortgage costs, while household size is included to capture variation in utility and fuel costs.


Our weather event data is obtained from the National Oceanic and Atmospheric Administration (NOAA) through Google Cloud's BigQuery platform. We access the public dataset 'bigquery-public-data.noaa_historic_severe_storms.storms' using Python's BigQuery client library. To establish the connection, we create a service account and associated credentials file that allows secure access to the Google Cloud API.

The query extracts yearly event data at the county level, including state and county FIPS codes for precise geographic identification. For each county, we collect the number of occurrences of different types of severe weather events. The initial format of the NOAA data presents individual reports of specific weather events by county and year (for example, one row would read as "King County, Washington had 4 reports of debris flow in 2013"). To make this data more amenable to analysis, we transform it using a pivot_wider() function to create a format where each county-year combination represents a single row. We then aggregate all event reports for each county-year into a total event count, which serves as our primary measure of severe weather activity in our analysis.

The data is organized by year, state, and county, with corresponding FIPS codes to ensure accurate matching with our census data. The query groups events by these geographic identifiers and event type, providing a comprehensive count of different severe weather occurrences for each location and time period. This structured approach allows us to create a consistent dataset that can be merged with our housing cost data for subsequent analysis.

Exploratory Data Analysis

Are storms correlated b y county?

```{r}
#| echo: false
#| message: false

ggplot(mapping = aes(
  x = noaa_2018_bothyearcounties$total_events,
  y = noaa_2023_bothyearcounties$total_events,
  alpha = 0.5
)) +
  geom_point(color = 'goldenrod4', shape = "*", size = 5) +
  labs(
    title = "Five-Year Change in Weather Events",
    subtitle = "Counties Where Events > 0, per NOAA") +
  xlab("2018 | Total Events") +
  ylab("2023 | Total Events") +
  theme_bw() +
  theme(legend.position = "none") +
  theme(title = element_text(color = 'navy')) +
  coord_equal(ratio = 1, expand = TRUE, xlim = c(0, 750), ylim = c(0, 750))
```

Let's zoom in on the majority of counties:

```{r}
#| echo: false
#| message: false

ggplot(mapping = aes(
  x = noaa_2018_bothyearcounties$total_events,
  y = noaa_2023_bothyearcounties$total_events,
  alpha = 0.5
)) +
  geom_point(color = 'goldenrod4', shape = "*", size = 5) +
  labs(
    title = "Five-Year Change in Weather Events",
    subtitle = "Counties Where Events > 0, per NOAA") +
  xlab("2018 | Total Events") +
  ylab("2023 | Total Events") +
  theme_bw() +
  theme(legend.position = "none") +
  theme(title = element_text(color = 'navy')) +
  coord_equal(ratio = 1, expand = TRUE, xlim = c(0, 310), ylim = c(0, 310))
```

…and zoom in even closer:

```{r}
#| echo: false
#| message: false

ggplot(mapping = aes(
  x = noaa_2018_bothyearcounties$total_events,
  y = noaa_2023_bothyearcounties$total_events,
  alpha = 0.5
)) +
  geom_point(color = 'goldenrod4', shape = "*", size = 5) +
  labs(
    title = "Five-Year Change in Weather Events",
    subtitle = "Counties Where Events > 0, per NOAA") +
  xlab("2018 | Total Events") +
  ylab("2023 | Total Events") +
  theme_bw() +
  theme(legend.position = "none") +
  theme(title = element_text(color = 'navy')) +
  coord_equal(ratio = 1, expand = TRUE, xlim = c(0, 150), ylim = c(0, 150))
```

A linear model for this relationship:

```{r}
#| echo: false
#| message: false

model <- lm(noaa_2023_bothyearcounties$total_events ~ noaa_2018_bothyearcounties$total_events)
summary(model)
```
2018 events and 2023 events are highly correlated by county, which makes sense because weather is generally stable within a 5-year period.  Overall, though, there is a very slight positive relationship between year-change and total events -- demonstrating climate change and the greater prevalence of extreme weather events.

Delineating by event type:

```{r}
#| echo: false
#| message: false

event_sum_bothyears <- noaa_1_county |>
  select(-c(county, state_bad, county_state, fips_ovr)) |>
  pivot_longer(cols = everything()) |>
  group_by(name) |>
  summarise(instances = sum(value)) |>
  filter(name != "year", name != "total_events", name != "state_fips_code", name != "cz_fips_code") |>
  rename(event_type = name)

event_sum_2018 <- noaa_2018 |>
  select(-c(county, state_bad, county_state, fips_ovr)) |>
  pivot_longer(cols = everything()) |>
  group_by(name) |>
  summarise(instances = sum(value)) |>
  filter(name != "year", name != "state_fips_code", name != "cz_fips_code") |>
  rename(event_type = name)

event_sum_2023 <- noaa_2023 |>
  select(-c(county, state_bad, county_state, fips_ovr)) |>
  pivot_longer(cols = everything()) |>
  group_by(name) |>
  summarise(instances = sum(value)) |>
  filter(name != "year", name != "state_fips_code", name != "cz_fips_code") |>
  rename(event_type = name)
```

Floods:

```{r}
#| echo: false
#| message: false

floods <- c("flood", "flash flood", "coastal flood", "lakeshore flood")

floods_bothyears <- event_sum_bothyears |>
  filter(event_type %in% floods) |>
  arrange(desc(instances))

floods_2018 <- event_sum_2018 |>
  filter(event_type %in% floods) |>
  arrange(desc(instances))

floods_2023 <- event_sum_2023 |>
  filter(event_type %in% floods) |>
  arrange(desc(instances))

summary(floods_bothyears)

head(floods_bothyears)
```

```{r}
#| echo: false
#| message: false

census_data_total <- census_data_total |>
  mutate(county = str_to_upper(county, locale = "en")) |>
  mutate(fips_ovr = paste(county, as.character(state_fips), as.character(county_fips), sep = "__"))

census2013 <- census_data_total |>
  filter(year == 2013)

census2018 <- census_data_total |>
  filter(year == 2018)

census2023 <- census_data_total |>
  filter(year == 2023)

exclusive_counties_census <- setdiff(census2023$county, noaa_2023_bothyearcounties$county)
exclusive_counties_noaa <- setdiff(noaa_2023_bothyearcounties$county, census2023$county)
exclusive_counties <- c(exclusive_counties_census, exclusive_counties_noaa)
length(exclusive_counties)

census2023_noaa2023 <-
  full_join(noaa_2023_bothyearcounties, census2023, 
            by = "fips_ovr")

census2023_noaa2023 <- census2023_noaa2023 |>
  filter(!(county.x %in% exclusive_counties)) |>
  filter(!(county.y %in% exclusive_counties))
```

```{r}
#| echo: false
#| message: false

main_set <-
  full_join(noaa_1_county, census_data_total,
            by = join_by(year == year, fips_ovr == fips_ovr))

main_set <- main_set |>
  filter(!(county.x %in% exclusive_counties)) |>
  filter(!(county.y %in% exclusive_counties)) |>
  select(fips_ovr, state, year, total_events, owner_cost_median, everything()) |>
  drop_na()
```

More EDA:

```{r}
#| echo: false
#| message: false

cost_hist <- ggplot(data = main_set, aes(x = owner_cost_median)) +
  geom_histogram(fill = 'darkred', binwidth = 300) +
  theme_bw() +
  labs(
    title = "Median of Estimated Monthly Homeowner Costs",
    subtitle = ("(with insurance)")
  ) +
  xlab("Owner Cost Median ($)") +
  ylab("Number of US Counties")

cost_hist
```

```{r}
#| echo: false
#| message: false

events_boxplot <- ggplot(data = main_set, aes(x = total_events, y = as.factor(year))) +
  geom_boxplot() +
  labs(title = "Weather Events Sorted by Year") +
  coord_flip() +
  ylab("Year") +
  xlab("Total Reported Severe Events") +
  theme_bw()

events_boxplot
```

```{r}
#| echo: false
#| message: false

events_boxplot_no_outliers <- ggplot(data = main_set, aes(x = total_events, y = as.factor(year))) +
  geom_boxplot(outlier.shape = NA) +
  scale_x_continuous(limits = quantile(main_set$total_events, c(0.1, 0.9))) +
  labs(title = "Weather Events Sorted by Year", 
       subtitle = "Outliers Removed") +
  coord_flip() +
  ylab("Year") +
  xlab("Total Reported Severe Events") +
  theme_bw()

events_boxplot_no_outliers
```

```{r}
#| echo: false
#| message: false

events_violin <- ggplot(data = main_set, aes(x = total_events, y = as.factor(year), fill = year)) +
  geom_violin() +
  xlab("Total Reported Severe Events (via NOAA)") +
  ylab("Year") +
  labs(title = "Weather Events Sorted by Year",
       subtitle = ) +
  theme_bw() +
  theme(legend.position = "none",
        title = element_text(color = 'maroon')) +
  coord_flip()

events_violin
```

# Methods

We merge NOAA data and ACS data using a Full Join, based on a combination of county names and Federal Information Processing Standard (FIPS) geographic codes.  This allows for counties with the same name but different geographies (for example, there are 25 Jefferson counties in the United States) to not merge any data.

Once we have this main, joined dataset, we are able to run statistical analyses.  Wanting to check 2013 weather events’ possible effects on 2018’s homeowner costs in Clark County, Kentucky – as one of many examples – we also make a shifted dataset.  This set includes a new variable that applied a positive 5-year shift on NOAA data, allowing for easy modeling based on – again, as one example – 2018 weather reporting on 2023 costs by county.

The unshifted linear model uses the unshifted weather data to predict housing costs in the same year: 2013 costs by 2013 weather events in each county, 2018 costs by 2018 weather events in each county, and 2023 costs by 2023 weather events in each county.  The model begins with an intercept of $11,777.40 and predicts a decrease of $1.96 in annual housing costs for each extreme weather event in the county.  This model is statistically significant, with a p-value of 0.0007; the linear model has an adjusted R-squared that is effectively 0.

The shifted linear model uses the shifted dataset to predict housing costs 5 years later: 2018 costs by 2013 weather events in each county and 2023 costs by 2018 weather events in each county.  The model begins with an intercept of $11,351.34 and predicts a decrease of $1.31 in annual housing costs for each extreme weather event in the county five years previous.  This model is not statistically significant, with a p-value of 0.0536; the model also has an adjusted R-squared that is approaching 0.

We also estimate a fixed effect model to explore how homeowner costs relate to natural disaster events within each state over time. Our regression equation is structured as:

Yti = BXti + fixed effects

In this equation, Yti represents the logarithm of median owner cost in county i at time t. The explanatory variables Xti include our main variable of interest - the logarithm of total number of events - along with the following control variables: the logarithm of median house value and the average household size at the county level. The fixed effects component captures county-specific characteristics that remain constant over time. By using fixed effects at the county level, we control for time-invariant factors specific to each county that might influence homeowner costs.

This model specification allows us to examine how changes in natural disaster events within a county relate to changes in homeowner costs, while controlling for other relevant factors and accounting for county-specific characteristics. The use of logarithmic transformations helps us interpret the relationships in terms of percentage changes and helps address potential non-linearities in the relationships between variables.

# Linear Model 

```{r}
model_1 <- lm(owner_cost_median ~ total_events, data = main_set)
summary(model_1)
```

A graphical representation of the above:

```{r}
model_1_plot <- ggplot(data = main_set, aes(
  x = total_events,
  y = owner_cost_median,
  color = cut(year, breaks = c(2012, 2014, 2017, 2019, 2022, 2024)),
  alpha = 0.5
)) +
  geom_point() +
  theme_bw() +
  labs(title = "Major Weather Events' Effect on Costs") +
  labs(subtitle = "By U.S. County, By Year") + 
  xlab("Total Major Weather Events in Year") +
  ylab("Owner Cost Median ($)") +
  scale_color_manual(values = c('green', 'darkred', 'blue'), 
                     labels = c("2013", "2018", "2023")) +
  theme(legend.title = element_blank()) +
  theme(plot.title = element_text(color = "navy")) +
  theme(plot.subtitle = element_text(color = "navy")) +
  guides(alpha = "none")

model_1_plot
```

How about we fit a line of best fit on that?

```{r}
model_1_plot_lm <- model_1_plot +
  geom_smooth(method = "lm", se = FALSE)

model_1_plot_lm
```

Split the above plot into years:

```{r}
model_1_faceted_plot <- ggplot(data = main_set, aes(
  x = total_events,
  y = owner_cost_median,
  color = cut(year, breaks = c(2012, 2014, 2017, 2019, 2022, 2024)),
  alpha = 0.5
)) +
  geom_point() +
  theme_bw() +
  labs(title = "Major Weather Events' Effect on Costs") +
  labs(subtitle = "By U.S. County Median, By Year") + 
  xlab("Total Major Weather Events") +
  ylab("Monthly Homeowner Costs (with insurance), $US") +
  scale_color_manual(values = c('darkgreen', 'darkred', 'blue'), 
                     labels = c("2013", "2018", "2023")) +
  theme(legend.title = element_blank()) +
  theme(plot.title = element_text(color = "goldenrod4")) +
  theme(plot.subtitle = element_text(color = "goldenrod4")) +
  theme(legend.position = "none") +
  guides(alpha = "none") +
  geom_smooth(method = "lm", se = FALSE, color = 'black') +
  facet_wrap(~ year)

model_1_faceted_plot
```

Shifting NOAA years to better plot effects YoY:

```{r}

noaa_1_county_shifted <- noaa_1_county |>
  mutate(year_shift = year + 5) |>
  rename(year_actual = year, year = year_shift) |>
  filter(year != 2028, year != 2013)

main_set_shifted <-
  full_join(noaa_1_county_shifted, census_data_total,
            by = join_by(year == year, fips_ovr == fips_ovr))

main_set_shifted <- main_set_shifted |>
  filter(!(county.x %in% exclusive_counties)) |>
  filter(!(county.y %in% exclusive_counties)) |>
  select(fips_ovr, state, year, year_actual, total_events, owner_cost_median, everything()) |>
  drop_na()
```

```{r}
model_2 <- lm(owner_cost_median ~ total_events, data = main_set_shifted)
summary(model_2)
```

```{r}
model_2_plot <- ggplot(data = main_set, aes(
  x = total_events,
  y = owner_cost_median,
  color = cut(year, breaks = c(2017, 2019, 2022, 2024)),
  alpha = 0.5
)) +
  geom_point() +
  theme_bw() +
  labs(title = "Major Weather Events' Effect on Costs") +
  labs(subtitle = "By U.S. County, By Year") + 
  xlab("Total Major Weather Events in Year, 5 Years Before") +
  ylab("Owner Cost Median ($)") +
  scale_color_manual(values = c('red', 'orange'), 
                     labels = c("2018", "2023")) +
  theme(legend.title = element_blank()) +
  theme(plot.title = element_text(color = "navy")) +
  theme(plot.subtitle = element_text(color = "navy")) +
  guides(alpha = "none")

model_2_plot
```

# Results

Our analysis using fixed effects models reveals some patterns in how natural disasters relate to homeowner costs. The fe_model2 shows a slight positive relationship between the logarithm of total events and homeowner costs when looking at changes within counties, though this relationship is not statistically significant. Interestingly, fe_model2 also shows that the log of median house value has a negative correlation with owner costs, which contradicts what prior research would typically expect.

When we examine fe_model4, which uses the lag of the logarithm of total events to predict the current logarithm of median owner cost, we find a negative relationship. This unexpected finding suggests that either our model specification is not capturing the true relationship or that there are underlying factors we have not considered. It is important to note that using the lagged variable in fe_model4 results in losing approximately one-third of our data points (2013 housing data and 2024 weather event data), while still maintaining a separate predictor for each county in our fixed effects estimation.

Our LASSO analysis provides additional insights. In this model, the log_total_events variable shrinks to zero, indicating it may not be as strong a predictor as initially thought. The LASSO approach estimates most of the fixed effects for the counties, suggesting that county-specific characteristics play a significant role in determining homeowner costs. This comprehensive analysis raises questions about the true nature of the relationship between natural disasters and homeowner costs, and suggests we might need to explore additional factors or alternative model specifications.

Panel
```{r}

#write_xlsx(main_set, "Data/main_set.xlsx")

# Create panel data structure
panel_data <- main_set %>%
  arrange(fips_ovr, year) %>%
  group_by(fips_ovr) %>%
  mutate(
    total_events_lagged = dplyr::lag(total_events),
    log_owner_cost = log(owner_cost_median),
    log_total_events = log(total_events+1),
    log_total_events_lagged = log(total_events_lagged+1),
    log_house_value_median = log(house_value_median),
    log_income_median = log(income_median),
    log_household_size_average = log(household_size_average)
  ) %>%
  select(fips_ovr, year, owner_cost_median, total_events,
         total_events_lagged, everything()) |>
  ungroup()
panel_data_plm <- pdata.frame(panel_data, index = c("fips_ovr", "year"))
```

Fixed effects model
```{r}
fe_model1 <- plm(log_owner_cost ~ log_total_events + log_house_value_median +
                log_income_median + log_household_size_average, 
                data = panel_data_plm,
                model = "within")

fe_model2 <- plm(log_owner_cost ~ log_total_events + log_house_value_median +
                log_household_size_average, 
                data = panel_data_plm,
                model = "within")

fe_model3 <- plm(log_owner_cost ~ log_total_events + log_house_value_median,
                data = panel_data_plm,
                model = "within")

fe_model4 <- plm(log_owner_cost ~ log_total_events_lagged + log_house_value_median,
                data = panel_data_plm,
                model = "within")

fe_model <- fe_model4

clustered_results <- coeftest(fe_model, vcov = vcovHC(fe_model, type = "HC1", cluster = "group"))
print(clustered_results)
```

Lasso model
```{r}

county_dummies <- model.matrix(~ factor(fips_ovr) - 1, data = panel_data_plm)

X <- model.matrix(~ log_total_events + log_house_value_median - 1, 
                 data = panel_data_plm)

X_full <- cbind(X, county_dummies)

y <- panel_data_plm$log_owner_cost

cv_lasso <- cv.glmnet(X_full, y, alpha = 1)

lasso_model <- glmnet(X_full, y, alpha = 1, lambda = cv_lasso$lambda.min)

coef(lasso_model)
```

Presentation
```{r}

stargazer(fe_model, 
          type = "text",  # Use "html" or "latex" for other formats
          title = "Fixed Effects Regression Results",
          covariate.labels = c("Log Total Events",
                             "Log House Value",
                             "Log Household Size"),
          dep.var.labels = "Log Owner Cost",
          digit.separator = ",",
          digits = 3,
          model.numbers = FALSE,
          se = sqrt(diag(vcovHC(fe_model, type = "HC1", cluster = "group"))), # Use clustered SE
          star.cutoffs = c(0.05, 0.01, 0.001),
          add.lines = list(
            c("County Fixed Effects", "Yes"),
            c("Year Fixed Effects", "No"),
            c("Clustered SE", "County")
          ))
```

# Discussion

Our analysis concludes that natural disasters and extreme weather events are not major statistical predictors of homeowner costs and/or insurance pricing.  This analysis does come with some caveats, such as the intent and quality of NOAA’s reporting and the lack of an insurance-only variable in the Census data – so it is not a thorough analysis of a possible relationship.

It is possible that the relationship between storm events and homeowner costs is being obscured by variation across counties. Counties with relatively milder climates and fewer storms where we perhaps would not expect as much of a change in homeowner costs, are a high proportion of our dataset. Perhaps further work could investigate outlier counties with more extreme weather events to see if there is a relationship to homeowner costs, or the analysis could be done at the state level. It could also be interesting to compare the counties in the storms dataset to counties that experienced no extreme storm events, or to group the counties in the dataset by number of storms to compare counties with less storms against counties with more storms. 

Future work could include an investigation of NOAA’s data, delineating housing costs by ZIP code instead of by county, and the incorporation of county-wide economic data to use as control variables in modeling.

Future work could also explore this problem by storm type, explain changes in storm type incidence and perhaps evaluate whether certain storm types are related to any changes in homeowner insurance costs. Isolating types of storms that are more likely to cause structural damage to homes, such as floods, wildfires and hurricanes, could perhaps improve upon our results.

Future work would benefit from more precise and complete data on current and historical homeowner insurance costs; the same benefit would apply to weather event data.

\clearpage

# References
